{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resting state features calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from nice import Markers\n",
    "from nice.markers import (PowerSpectralDensity,\n",
    "                          PowerSpectralDensitySummary,\n",
    "                          PowerSpectralDensityEstimator,\n",
    "                          KolmogorovComplexity,\n",
    "                          PermutationEntropy,\n",
    "                          SymbolicMutualInformation)\n",
    "import winsound\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\Anaconda3\\Projects\\EEG ML project\n"
     ]
    }
   ],
   "source": [
    "# load basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set directories\n",
    "# %cd D:/Programy/Anaconda3/Projects/EEG ML project # working directory\n",
    "%cd D:\n",
    "pkls = './Pickles/' # objects & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions for markers\n",
    "from scipy.stats import trim_mean\n",
    "def mean_trim80(a, axis=0):  \n",
    "    return trim_mean(a, proportiontocut=.1, axis=axis)\n",
    "def entropy(a, axis=0): \n",
    "    return -np.nansum(a * np.log(a), axis=axis) / np.log(a.shape[axis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = 'python'  # maximum compatibility across platforms\n",
    "\n",
    "# define one base estimator to avoid recomputation later on\n",
    "# when making another set of marker, also recompute the base_psd\n",
    "psds_params = dict(n_fft = 384,     # length of the FFT used (if None: the FFT length is nperseg)\n",
    "                   n_overlap = 192, # n of points to overlap between segments (if None: then nperseg/2)\n",
    "                   n_jobs = 'auto', # cpu cores\n",
    "                   nperseg = 4096)  # length of each segment (samples)\n",
    "\n",
    "base_psd = PowerSpectralDensityEstimator(\n",
    "    psd_method='welch', tmin=None, tmax=None, fmin=1., fmax=45.,\n",
    "    psd_params=psds_params, comment='default')\n",
    "\n",
    "\n",
    "# resting-state compatible markers, gamma band removed\n",
    "markers = Markers([\n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=1., fmax=4.,\n",
    "                         normalize=False, comment='delta'),\n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=1., fmax=4.,\n",
    "                         normalize=True, comment='deltan'),\n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=4., fmax=8.,\n",
    "                         normalize=False, comment='theta'),\n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=4., fmax=8.,\n",
    "                         normalize=True, comment='thetan'),\n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=8., fmax=12.,\n",
    "                         normalize=False, comment='alpha'),\n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=8., fmax=12.,\n",
    "                         normalize=True, comment='alphan'),\n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=12., fmax=30.,\n",
    "                         normalize=False, comment='beta'),\n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=12., fmax=30.,\n",
    "                         normalize=True, comment='betan'),\n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=30., fmax=45.,\n",
    "                         normalize=False, comment='gamma'),\n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=30., fmax=45.,\n",
    "                         normalize=True, comment='gamman'),\n",
    "    \n",
    "    PowerSpectralDensity(estimator=base_psd, fmin=1., fmax=45.,\n",
    "                         normalize=False, comment='summary_se'),\n",
    "    PowerSpectralDensitySummary(estimator=base_psd, fmin=1., fmax=45.,  # aka Spectral Entropy\n",
    "                                percentile=.5, comment='summary_msf'),\n",
    "    PowerSpectralDensitySummary(estimator=base_psd, fmin=1., fmax=45.,\n",
    "                                percentile=.9, comment='summary_sef90'),\n",
    "    PowerSpectralDensitySummary(estimator=base_psd, fmin=1., fmax=45.,\n",
    "                                percentile=.95, comment='summary_sef95'),\n",
    "    PermutationEntropy(tmin=None, tmax=0.6, backend=backend),\n",
    "    SymbolicMutualInformation(\n",
    "        tmin=None, tmax=0.6, method='weighted', backend=backend,\n",
    "        method_params={'nthreads': 'auto', 'bypass_csd': True}, # csd needs to be skipped\n",
    "        comment='weighted'),\n",
    "    KolmogorovComplexity(tmin=None, tmax=0.6, backend=backend,\n",
    "                         method_params={'nthreads': 'auto'}),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0041fdc961ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# optional: compute markers before reducing them (explore and plot)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmarkers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fullmarkers1.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# optional: explore PSDs used for the marker computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "# # optional: compute markers before reducing them (explore and plot)\n",
    "# markers.fit(epochs)\n",
    "# markers.save('fullmarkers1.hdf5', overwrite = True)\n",
    "\n",
    "# # optional: explore PSDs used for the marker computation\n",
    "# psd = base_psd.data_\n",
    "# freqs = base_psd.freqs_\n",
    "\n",
    "#%matplotlib widget\n",
    "# plt.figure()\n",
    "# plt.semilogy(freqs, np.mean(psd, axis=0).T, alpha=0.1, color='black')\n",
    "# plt.xlim(2, 40)\n",
    "# plt.ylabel('log(psd)')\n",
    "# plt.xlabel('Frequency [Hz]')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\Anaconda3\\Projects\\EEG ML project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# local computer\n",
    "%cd D:\n",
    "path = Path('D:/Programy/Anaconda3/Projects/EEG ML project/Epochs clean/')\n",
    "epo_list = list(path.glob('*.fif'))\n",
    "len(epo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Bartek\\JupyterLab Projects\\ML EEG project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remote computer\n",
    "%cd D:\n",
    "path = Path('D:/Marcin/OneDrive - Uniwersytet Jagiello≈Ñski/Nauka/Projekty/2020.02 - Bartek ML EEG/Epochs clean/')\n",
    "epo_list = list(path.glob('*.fif'))\n",
    "len(epo_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and compute reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set timer\n",
    "start_time = time.time()\n",
    "\n",
    "# settings\n",
    "nparticipants     = 2                     # n of participants to append\n",
    "epochs_all_funs   = [mean_trim80, np.std] # reduction functions for epochs\n",
    "channels_all_funs = [np.mean, np.std]     # reduction functions for channels\n",
    "\n",
    "# column names\n",
    "nice_columns = ['d','d_norm','t','t_norm','a','a_norm','b','b_norm','g', 'g_norm',\n",
    "                'summ_se','summ_msf','summ_sef90','summ_sef95','PE', 'wSMI', 'K']\n",
    "\n",
    "# nested loops\n",
    "r3 = pd.DataFrame() # empty df for appending participnts\n",
    "loopstep_n = 0\n",
    "\n",
    "# iterate over participants\n",
    "# for file in epo_list[:nparticipants]:\n",
    "for file in (epo_list[:6] + epo_list[10:14]): # for testing\n",
    "    \n",
    "    epochs = mne.read_epochs(fname = file) # read epoched eeg data\n",
    "    x_features = np.empty((len(epochs), len(markers))) # empty array for reductions\n",
    "    r2 = pd.DataFrame(columns = ['epoch','id']) # empty df for appending participnts\n",
    "    \n",
    "    # iterate over function\n",
    "    for epochs_fun in epochs_all_funs:\n",
    "        for channels_fun in channels_all_funs:\n",
    "\n",
    "            loopstep_n += 1\n",
    "            print('\\n - Loop step %i -'     % loopstep_n)\n",
    "            print('Epochs   function: %s'   % epochs_fun.__name__)\n",
    "            print('Channels function: %s\\n' % channels_fun.__name__)\n",
    "\n",
    "            # set reduction parameters\n",
    "            reduction_params = {\n",
    "                'PowerSpectralDensity': {\n",
    "                    'reduction_func': [\n",
    "                        {'axis': 'frequency', 'function': np.sum},\n",
    "                        {'axis': 'epochs', 'function': epochs_fun},\n",
    "                        {'axis': 'channels', 'function': channels_fun}]\n",
    "                },\n",
    "                'PowerSpectralDensitySummary': {\n",
    "                    'reduction_func': [\n",
    "                        {'axis': 'epochs', 'function': epochs_fun},\n",
    "                        {'axis': 'channels', 'function': channels_fun}]\n",
    "                },\n",
    "                'SymbolicMutualInformation': {\n",
    "                    'reduction_func': [\n",
    "                        {'axis': 'epochs', 'function': epochs_fun},\n",
    "                        {'axis': 'channels', 'function': channels_fun},\n",
    "                        {'axis': 'channels_y', 'function': channels_fun}]\n",
    "                },\n",
    "                'PermutationEntropy': {\n",
    "                    'reduction_func': [\n",
    "                        {'axis': 'epochs', 'function': epochs_fun},\n",
    "                        {'axis': 'channels', 'function': channels_fun}]\n",
    "                },\n",
    "                'KolmogorovComplexity': {\n",
    "                    'reduction_func': [\n",
    "                        {'axis': 'epochs', 'function': epochs_fun},\n",
    "                        {'axis': 'channels', 'function': channels_fun}]\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # compute markers over epochs\n",
    "            for ii in range(len(epochs)):\n",
    "                markers.fit(epochs[ii])\n",
    "                x_features[ii, :] = markers.reduce_to_scalar(marker_params=reduction_params) # reduce\n",
    "                for marker in markers.values():\n",
    "                    delattr(marker, 'data_')\n",
    "                delattr(base_psd, 'data_')\n",
    "        \n",
    "            # merge reduction functions\n",
    "            r1 = pd.DataFrame.from_records(x_features) # to df\n",
    "            \n",
    "            if file.stem[:5] == 'video':\n",
    "                r1.insert(0, 'id', file.stem[6:11]) # add id (video session) \n",
    "            else:\n",
    "                r1.insert(0, 'id', file.stem[:5]) # add id (open/closed eyes)\n",
    "                        \n",
    "            r1 = r1.rename(columns=dict(zip(r1.columns[1:], nice_columns)))\n",
    "            r1.reset_index(inplace = True)\n",
    "            r1.rename(columns={'index' : 'epoch'}, inplace = True) \n",
    "            r1.columns = r1.columns.map(lambda x: x + ('_' + epochs_fun.__name__[0] + channels_fun.__name__[0]) \\\n",
    "                                        if x != 'id' and x != 'epoch' else x) # suffix functions abbreviations\n",
    "            r2 = r2.merge(r1, how = 'right', on = ['id', 'epoch'])\n",
    "        \n",
    "    # append participants\n",
    "    r3 = r3.append(r2)\n",
    "    r3.reset_index(inplace = True, drop = True)    \n",
    "    \n",
    "# get execution time\n",
    "print(\"--- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "winsound.Beep(frequency = 440, duration = 800) # beep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "with open('features_r3.pkl', 'wb') as handle:\n",
    "    pickle.dump(r3, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\Anaconda3\\Projects\\EEG ML project\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "# %cd D:\n",
    "with open(pkls +'r3.pkl', 'rb') as handle:\n",
    "    r3 = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
