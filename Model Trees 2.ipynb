{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Random Forests and Extra-Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\Anaconda3\\Projects\\EEG ML project\n"
     ]
    }
   ],
   "source": [
    "# load basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set directories\n",
    "# %cd D:/Programy/Anaconda3/Projects/EEG ML project # working directory\n",
    "%cd D:\n",
    "pkls = './Pickles/' # objects & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 94)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load split sets, eeg only\n",
    "with open(pkls +'xy_train.pkl', 'rb') as handle:\n",
    "    x_train = pickle.load(handle)\n",
    "    y_train = pickle.load(handle)\n",
    "y_train.shape\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra-Trees: DOC-Forest model\n",
    "Replicating settings from Endemann et al., 2018 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
       "                     criterion='entropy', max_depth=4, max_features=1,\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original Endemann et al. model\n",
    "n_estimators = 200 # default: 2000\n",
    "\n",
    "doc = ExtraTreesClassifier(n_estimators=n_estimators, max_features=1, criterion='entropy',\n",
    "        max_depth=4, random_state=42, class_weight='balanced')\n",
    "\n",
    "doc.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc mean</th>\n",
       "      <th>acc 2sd</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>f1 2sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <td>0.495</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acc mean  acc 2sd  f1 mean  f1 2sd\n",
       "doc     0.495    0.103    0.473   0.099"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "cv = 5\n",
    "scores = cross_val_score(doc, x_train, y_train.values.ravel(), cv=cv)\n",
    "scoresf1 = cross_val_score(doc, x_train, y_train.values.ravel(), cv=cv, scoring='f1_weighted')\n",
    "\n",
    "doc_res = pd.DataFrame(data = [round(scores.mean(),3), round(scores.std() * 2, 3), \n",
    "                               round(scoresf1.mean(),3), round(scoresf1.std() * 2,3)]).T\n",
    "doc_res.columns = ['acc mean', 'acc 2sd', 'f1 mean','f1 2sd']\n",
    "doc_res.index = ['doc']\n",
    "doc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Pickles/doc_forest.pkl', 'wb') as handle:\n",
    "    pickle.dump(doc, handle)\n",
    "    pickle.dump(doc_res, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkls + 'doc_forest.pkl', 'rb') as handle:\n",
    "    doc = pickle.load(handle)\n",
    "    doc_res = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra-Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 143 out of 150 | elapsed:    3.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    4.3s finished\n"
     ]
    }
   ],
   "source": [
    "# 1st run\n",
    "cv = 10\n",
    "n_estimators = 1000 # go for ~2000\n",
    "param_grid = {'max_depth': [2, 4, 8, 16], \n",
    "              'max_features': ['log2', 'auto'],\n",
    "              'max_leaf_nodes': [8, 16, 24],\n",
    "              'min_samples_leaf': [1,2,3]}\n",
    "\n",
    "scorers = {'accuracy': make_scorer(accuracy_score),\n",
    "           'f1'      : make_scorer(f1_score, average = 'weighted')}\n",
    "grid = GridSearchCV(ExtraTreesClassifier(n_estimators = n_estimators), param_grid, refit='accuracy', verbose=1, \n",
    "                    scoring = scorers, return_train_score=True, cv = cv, n_jobs = -1)\n",
    "\n",
    "grid.fit(x_train, y_train.values.ravel())\n",
    "best_extr = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc mean</th>\n",
       "      <th>acc 2sd</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>f1 2sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>extr</th>\n",
       "      <td>0.4911</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.4851</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc mean  acc 2sd  f1 mean  f1 2sd\n",
       "extr    0.4911   0.0581   0.4851   0.065"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate and save\n",
    "best_extr_res = round(pd.DataFrame(index = ['extr'], data  = \n",
    "          {'acc mean':[grid.cv_results_['mean_test_accuracy'][grid.best_index_]],\n",
    "           'acc 2sd': [2*grid.cv_results_['std_test_accuracy'][grid.best_index_]],\n",
    "           'f1 mean': [grid.cv_results_['mean_test_f1'][grid.best_index_]],\n",
    "           'f1 2sd' : [2*grid.cv_results_['std_test_f1'][grid.best_index_]]}),4)\n",
    "best_extr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc mean: 0.9714\n",
      "training f1  mean: 0.9714\n"
     ]
    }
   ],
   "source": [
    "# train set score for comparison\n",
    "best_extr.fit(x_train, y_train.values.ravel())\n",
    "print(\"training acc mean: {:.4f}\".format(\n",
    "    best_extr.score(x_train, y_train)))\n",
    "print(\"training f1  mean: {:.4f}\".format(\n",
    "    f1_score(y_train, best_extr.predict(x_train), average = 'weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "with open('./Pickles/best_extr.pkl', 'wb') as handle:\n",
    "    pickle.dump(best_extr, handle)\n",
    "    pickle.dump(best_extr_res, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkls + 'best_extr.pkl', 'rb') as handle:\n",
    "    best_extr = pickle.load(handle)\n",
    "    best_extr_res = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random-Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 344 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:   30.7s finished\n"
     ]
    }
   ],
   "source": [
    "# RandomForest 1st run\n",
    "cv = 10\n",
    "n_estimators = 1000 # go for ~2000\n",
    "param_grid = {'max_depth': [2, 4, 8, 16], \n",
    "              'max_features': ['log2', 'auto'],\n",
    "              'max_leaf_nodes': [8, 16, 24],\n",
    "              'min_samples_leaf': [1,2,3]}\n",
    "\n",
    "scorers = {'accuracy': make_scorer(accuracy_score),\n",
    "           'f1'      : make_scorer(f1_score, average = 'weighted')}\n",
    "grid = GridSearchCV(RandomForestClassifier(n_estimators = n_estimators), param_grid, refit='accuracy', verbose=1, \n",
    "                    scoring = scorers, return_train_score=True, cv = cv, n_jobs = -1)\n",
    "\n",
    "grid.fit(x_train, y_train.values.ravel())\n",
    "best_forest = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=16, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc mean</th>\n",
       "      <th>acc 2sd</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>f1 2sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>forest</th>\n",
       "      <td>0.5361</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.5276</td>\n",
       "      <td>0.0711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc mean  acc 2sd  f1 mean  f1 2sd\n",
       "forest    0.5361   0.0627   0.5276  0.0711"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate and save\n",
    "best_forest_res = round(pd.DataFrame(index = ['forest'], data  = \n",
    "          {'acc mean':[grid.cv_results_['mean_test_accuracy'][grid.best_index_]],\n",
    "           'acc 2sd': [2*grid.cv_results_['std_test_accuracy'][grid.best_index_]],\n",
    "           'f1 mean': [grid.cv_results_['mean_test_f1'][grid.best_index_]],\n",
    "           'f1 2sd' : [2*grid.cv_results_['std_test_f1'][grid.best_index_]]}),4)\n",
    "best_forest_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc mean: 0.6250\n",
      "training f1  mean: 0.6228\n"
     ]
    }
   ],
   "source": [
    "# train set score for comparison\n",
    "best_forest.fit(x_train, y_train.values.ravel())\n",
    "print(\"training acc mean: {:.4f}\".format(\n",
    "    best_forest.score(x_train, y_train)))\n",
    "print(\"training f1  mean: {:.4f}\".format(\n",
    "    f1_score(y_train, best_forest.predict(x_train), average = 'weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('./Pickles/best_forest.pkl', 'wb') as handle:\n",
    "    pickle.dump(best_forest, handle)\n",
    "    pickle.dump(best_forest_res, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=16, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pkls + 'best_forest.pkl', 'rb') as handle:\n",
    "    best_forest = pickle.load(handle)\n",
    "    best_forest_res = pickle.load(handle)\n",
    "    \n",
    "# best_forest_res\n",
    "best_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_mm - 0.0556\n",
      "a_norm_mm - 0.03164\n",
      "d_ms - 0.02905\n",
      "d_norm_ms - 0.0271\n",
      "summ_msf_ms - 0.02469\n",
      "FT7 - 0.02388\n",
      "FC5 - 0.02206\n",
      "summ_sef90_ms - 0.02188\n",
      "b_ms - 0.02161\n",
      "C5 - 0.02126\n",
      "summ_sef95_ms - 0.02076\n",
      "b_norm_ms - 0.02029\n",
      "summ_sef95_mm - 0.01973\n",
      "F6 - 0.01967\n",
      "Fpz - 0.01912\n",
      "K_mm - 0.01816\n",
      "FT8 - 0.01803\n",
      "F7 - 0.01758\n",
      "a_norm_ms - 0.01723\n",
      "b_mm - 0.01663\n",
      "summ_msf_mm - 0.01648\n",
      "CP3 - 0.01608\n",
      "F8 - 0.01561\n",
      "d_mm - 0.01484\n",
      "t_ms - 0.01435\n",
      "a_ms - 0.01398\n",
      "summ_sef90_mm - 0.01353\n",
      "CP4 - 0.01194\n",
      "F4 - 0.01174\n",
      "FC6 - 0.01129\n",
      "summ_se_ms - 0.01107\n",
      "d_norm_mm - 0.01063\n",
      "b_norm_mm - 0.00983\n",
      "t_mm - 0.00927\n",
      "FC1 - 0.00907\n",
      "P3 - 0.00888\n",
      "C4 - 0.00887\n",
      "FC3 - 0.00853\n",
      "POz - 0.00844\n",
      "summ_se_mm - 0.00836\n",
      "T8 - 0.00812\n",
      "Fz - 0.00809\n",
      "T7 - 0.00789\n",
      "F2 - 0.00773\n",
      "Fp2 - 0.00771\n",
      "K_ms - 0.00758\n",
      "O1 - 0.00749\n",
      "PO8 - 0.00746\n",
      "FC2 - 0.00745\n",
      "F5 - 0.00735\n",
      "Fp1 - 0.0072\n",
      "CP5 - 0.00712\n",
      "F1 - 0.0071\n",
      "C6 - 0.00707\n",
      "C3 - 0.00685\n",
      "wSMI_ms - 0.00659\n",
      "TP8 - 0.00654\n",
      "P5 - 0.00642\n",
      "AF3 - 0.00638\n",
      "C2 - 0.00636\n",
      "P6 - 0.00635\n",
      "AF4 - 0.00624\n",
      "FC4 - 0.00596\n",
      "AF7 - 0.00573\n",
      "wSMI_mm - 0.00564\n",
      "P10 - 0.00558\n",
      "F3 - 0.00557\n",
      "Iz - 0.00551\n",
      "PO4 - 0.00549\n",
      "CPz - 0.00541\n",
      "AFz - 0.00538\n",
      "PE_mm - 0.00535\n",
      "PO7 - 0.0053\n",
      "t_norm_mm - 0.0053\n",
      "AF8 - 0.00521\n",
      "C1 - 0.00515\n",
      "TP7 - 0.00511\n",
      "FCz - 0.00499\n",
      "PE_ms - 0.00492\n",
      "CP6 - 0.00466\n",
      "CP1 - 0.00464\n",
      "CP2 - 0.00449\n",
      "P9 - 0.00443\n",
      "Oz - 0.00422\n",
      "P1 - 0.00383\n",
      "Pz - 0.00374\n",
      "P8 - 0.00345\n",
      "O2 - 0.00338\n",
      "P2 - 0.00322\n",
      "P4 - 0.00322\n",
      "PO3 - 0.00296\n",
      "Cz - 0.00288\n",
      "P7 - 0.00256\n",
      "t_norm_ms - 0.00085\n"
     ]
    }
   ],
   "source": [
    "# features importances\n",
    "for score, name in sorted(zip(doc.feature_importances_, x_train[1:]), reverse = True):\n",
    "    print(name, '-', round(score, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
